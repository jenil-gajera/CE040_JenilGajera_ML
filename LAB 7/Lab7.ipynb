{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1tp00CnCke"
      },
      "source": [
        "**Exercise 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW4N9jA1nJpq"
      },
      "source": [
        "Try logistic regression on BuyComputer dataset and set Random state=Your_RollNumber (last 3 digit of ID, incase if you donâ€™t have ID)\n",
        "\n",
        "implementation of logistic regression function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLVhnlKsniO4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "30saQTcSnpUv",
        "outputId": "a6fefb6c-f8ca-47b1-97d5-46f24975a6c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('BuyComputer.csv')\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywdI77_6twDV",
        "outputId": "d532b228-f118-4ce9-d428-fdd1136e1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label : \n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1]\n",
            "\n",
            "x : \n",
            " [[    19  19000]\n",
            " [    35  20000]\n",
            " [    26  43000]\n",
            " [    27  57000]\n",
            " [    19  76000]\n",
            " [    27  58000]\n",
            " [    27  84000]\n",
            " [    32 150000]\n",
            " [    25  33000]\n",
            " [    35  65000]\n",
            " [    26  80000]\n",
            " [    26  52000]\n",
            " [    20  86000]\n",
            " [    32  18000]\n",
            " [    18  82000]\n",
            " [    29  80000]\n",
            " [    47  25000]\n",
            " [    45  26000]\n",
            " [    46  28000]\n",
            " [    48  29000]\n",
            " [    45  22000]\n",
            " [    47  49000]\n",
            " [    48  41000]\n",
            " [    45  22000]\n",
            " [    46  23000]\n",
            " [    47  20000]\n",
            " [    49  28000]\n",
            " [    47  30000]\n",
            " [    29  43000]\n",
            " [    31  18000]\n",
            " [    31  74000]\n",
            " [    27 137000]\n",
            " [    21  16000]\n",
            " [    28  44000]\n",
            " [    27  90000]\n",
            " [    35  27000]\n",
            " [    33  28000]\n",
            " [    30  49000]\n",
            " [    26  72000]\n",
            " [    27  31000]\n",
            " [    27  17000]\n",
            " [    33  51000]\n",
            " [    35 108000]\n",
            " [    30  15000]\n",
            " [    28  84000]\n",
            " [    23  20000]\n",
            " [    25  79000]\n",
            " [    27  54000]\n",
            " [    30 135000]\n",
            " [    31  89000]\n",
            " [    24  32000]\n",
            " [    18  44000]\n",
            " [    29  83000]\n",
            " [    35  23000]\n",
            " [    27  58000]\n",
            " [    24  55000]\n",
            " [    23  48000]\n",
            " [    28  79000]\n",
            " [    22  18000]\n",
            " [    32 117000]\n",
            " [    27  20000]\n",
            " [    25  87000]\n",
            " [    23  66000]\n",
            " [    32 120000]\n",
            " [    59  83000]\n",
            " [    24  58000]\n",
            " [    24  19000]\n",
            " [    23  82000]\n",
            " [    22  63000]\n",
            " [    31  68000]\n",
            " [    25  80000]\n",
            " [    24  27000]\n",
            " [    20  23000]\n",
            " [    33 113000]\n",
            " [    32  18000]\n",
            " [    34 112000]\n",
            " [    18  52000]\n",
            " [    22  27000]\n",
            " [    28  87000]\n",
            " [    26  17000]\n",
            " [    30  80000]\n",
            " [    39  42000]\n",
            " [    20  49000]\n",
            " [    35  88000]\n",
            " [    30  62000]\n",
            " [    31 118000]\n",
            " [    24  55000]\n",
            " [    28  85000]\n",
            " [    26  81000]\n",
            " [    35  50000]\n",
            " [    22  81000]\n",
            " [    30 116000]\n",
            " [    26  15000]\n",
            " [    29  28000]\n",
            " [    29  83000]\n",
            " [    35  44000]\n",
            " [    35  25000]\n",
            " [    28 123000]\n",
            " [    35  73000]\n",
            " [    28  37000]\n",
            " [    27  88000]\n",
            " [    28  59000]\n",
            " [    32  86000]\n",
            " [    33 149000]\n",
            " [    19  21000]\n",
            " [    21  72000]\n",
            " [    26  35000]\n",
            " [    27  89000]\n",
            " [    26  86000]\n",
            " [    38  80000]\n",
            " [    39  71000]\n",
            " [    37  71000]\n",
            " [    38  61000]\n",
            " [    37  55000]\n",
            " [    42  80000]\n",
            " [    40  57000]\n",
            " [    35  75000]\n",
            " [    36  52000]\n",
            " [    40  59000]\n",
            " [    41  59000]\n",
            " [    36  75000]\n",
            " [    37  72000]\n",
            " [    40  75000]\n",
            " [    35  53000]\n",
            " [    41  51000]\n",
            " [    39  61000]\n",
            " [    42  65000]\n",
            " [    26  32000]\n",
            " [    30  17000]\n",
            " [    26  84000]\n",
            " [    31  58000]\n",
            " [    33  31000]\n",
            " [    30  87000]\n",
            " [    21  68000]\n",
            " [    28  55000]\n",
            " [    23  63000]\n",
            " [    20  82000]\n",
            " [    30 107000]\n",
            " [    28  59000]\n",
            " [    19  25000]\n",
            " [    19  85000]\n",
            " [    18  68000]\n",
            " [    35  59000]\n",
            " [    30  89000]\n",
            " [    34  25000]\n",
            " [    24  89000]\n",
            " [    27  96000]\n",
            " [    41  30000]\n",
            " [    29  61000]\n",
            " [    20  74000]\n",
            " [    26  15000]\n",
            " [    41  45000]\n",
            " [    31  76000]\n",
            " [    36  50000]\n",
            " [    40  47000]\n",
            " [    31  15000]\n",
            " [    46  59000]\n",
            " [    29  75000]\n",
            " [    26  30000]\n",
            " [    32 135000]\n",
            " [    32 100000]\n",
            " [    25  90000]\n",
            " [    37  33000]\n",
            " [    35  38000]\n",
            " [    33  69000]\n",
            " [    18  86000]\n",
            " [    22  55000]\n",
            " [    35  71000]\n",
            " [    29 148000]\n",
            " [    29  47000]\n",
            " [    21  88000]\n",
            " [    34 115000]\n",
            " [    26 118000]\n",
            " [    34  43000]\n",
            " [    34  72000]\n",
            " [    23  28000]\n",
            " [    35  47000]\n",
            " [    25  22000]\n",
            " [    24  23000]\n",
            " [    31  34000]\n",
            " [    26  16000]\n",
            " [    31  71000]\n",
            " [    32 117000]\n",
            " [    33  43000]\n",
            " [    33  60000]\n",
            " [    31  66000]\n",
            " [    20  82000]\n",
            " [    33  41000]\n",
            " [    35  72000]\n",
            " [    28  32000]\n",
            " [    24  84000]\n",
            " [    19  26000]\n",
            " [    29  43000]\n",
            " [    19  70000]\n",
            " [    28  89000]\n",
            " [    34  43000]\n",
            " [    30  79000]\n",
            " [    20  36000]\n",
            " [    26  80000]\n",
            " [    35  22000]\n",
            " [    35  39000]\n",
            " [    49  74000]\n",
            " [    39 134000]\n",
            " [    41  71000]\n",
            " [    58 101000]\n",
            " [    47  47000]\n",
            " [    55 130000]\n",
            " [    52 114000]\n",
            " [    40 142000]\n",
            " [    46  22000]\n",
            " [    48  96000]\n",
            " [    52 150000]\n",
            " [    59  42000]\n",
            " [    35  58000]\n",
            " [    47  43000]\n",
            " [    60 108000]\n",
            " [    49  65000]\n",
            " [    40  78000]\n",
            " [    46  96000]\n",
            " [    59 143000]\n",
            " [    41  80000]\n",
            " [    35  91000]\n",
            " [    37 144000]\n",
            " [    60 102000]\n",
            " [    35  60000]\n",
            " [    37  53000]\n",
            " [    36 126000]\n",
            " [    56 133000]\n",
            " [    40  72000]\n",
            " [    42  80000]\n",
            " [    35 147000]\n",
            " [    39  42000]\n",
            " [    40 107000]\n",
            " [    49  86000]\n",
            " [    38 112000]\n",
            " [    46  79000]\n",
            " [    40  57000]\n",
            " [    37  80000]\n",
            " [    46  82000]\n",
            " [    53 143000]\n",
            " [    42 149000]\n",
            " [    38  59000]\n",
            " [    50  88000]\n",
            " [    56 104000]\n",
            " [    41  72000]\n",
            " [    51 146000]\n",
            " [    35  50000]\n",
            " [    57 122000]\n",
            " [    41  52000]\n",
            " [    35  97000]\n",
            " [    44  39000]\n",
            " [    37  52000]\n",
            " [    48 134000]\n",
            " [    37 146000]\n",
            " [    50  44000]\n",
            " [    52  90000]\n",
            " [    41  72000]\n",
            " [    40  57000]\n",
            " [    58  95000]\n",
            " [    45 131000]\n",
            " [    35  77000]\n",
            " [    36 144000]\n",
            " [    55 125000]\n",
            " [    35  72000]\n",
            " [    48  90000]\n",
            " [    42 108000]\n",
            " [    40  75000]\n",
            " [    37  74000]\n",
            " [    47 144000]\n",
            " [    40  61000]\n",
            " [    43 133000]\n",
            " [    59  76000]\n",
            " [    60  42000]\n",
            " [    39 106000]\n",
            " [    57  26000]\n",
            " [    57  74000]\n",
            " [    38  71000]\n",
            " [    49  88000]\n",
            " [    52  38000]\n",
            " [    50  36000]\n",
            " [    59  88000]\n",
            " [    35  61000]\n",
            " [    37  70000]\n",
            " [    52  21000]\n",
            " [    48 141000]\n",
            " [    37  93000]\n",
            " [    37  62000]\n",
            " [    48 138000]\n",
            " [    41  79000]\n",
            " [    37  78000]\n",
            " [    39 134000]\n",
            " [    49  89000]\n",
            " [    55  39000]\n",
            " [    37  77000]\n",
            " [    35  57000]\n",
            " [    36  63000]\n",
            " [    42  73000]\n",
            " [    43 112000]\n",
            " [    45  79000]\n",
            " [    46 117000]\n",
            " [    58  38000]\n",
            " [    48  74000]\n",
            " [    37 137000]\n",
            " [    37  79000]\n",
            " [    40  60000]\n",
            " [    42  54000]\n",
            " [    51 134000]\n",
            " [    47 113000]\n",
            " [    36 125000]\n",
            " [    38  50000]\n",
            " [    42  70000]\n",
            " [    39  96000]\n",
            " [    38  50000]\n",
            " [    49 141000]\n",
            " [    39  79000]\n",
            " [    39  75000]\n",
            " [    54 104000]\n",
            " [    35  55000]\n",
            " [    45  32000]\n",
            " [    36  60000]\n",
            " [    52 138000]\n",
            " [    53  82000]\n",
            " [    41  52000]\n",
            " [    48  30000]\n",
            " [    48 131000]\n",
            " [    41  60000]\n",
            " [    41  72000]\n",
            " [    42  75000]\n",
            " [    36 118000]\n",
            " [    47 107000]\n",
            " [    38  51000]\n",
            " [    48 119000]\n",
            " [    42  65000]\n",
            " [    40  65000]\n",
            " [    57  60000]\n",
            " [    36  54000]\n",
            " [    58 144000]\n",
            " [    35  79000]\n",
            " [    38  55000]\n",
            " [    39 122000]\n",
            " [    53 104000]\n",
            " [    35  75000]\n",
            " [    38  65000]\n",
            " [    47  51000]\n",
            " [    47 105000]\n",
            " [    41  63000]\n",
            " [    53  72000]\n",
            " [    54 108000]\n",
            " [    39  77000]\n",
            " [    38  61000]\n",
            " [    38 113000]\n",
            " [    37  75000]\n",
            " [    42  90000]\n",
            " [    37  57000]\n",
            " [    36  99000]\n",
            " [    60  34000]\n",
            " [    54  70000]\n",
            " [    41  72000]\n",
            " [    40  71000]\n",
            " [    42  54000]\n",
            " [    43 129000]\n",
            " [    53  34000]\n",
            " [    47  50000]\n",
            " [    42  79000]\n",
            " [    42 104000]\n",
            " [    59  29000]\n",
            " [    58  47000]\n",
            " [    46  88000]\n",
            " [    38  71000]\n",
            " [    54  26000]\n",
            " [    60  46000]\n",
            " [    60  83000]\n",
            " [    39  73000]\n",
            " [    59 130000]\n",
            " [    37  80000]\n",
            " [    46  32000]\n",
            " [    46  74000]\n",
            " [    42  53000]\n",
            " [    41  87000]\n",
            " [    58  23000]\n",
            " [    42  64000]\n",
            " [    48  33000]\n",
            " [    44 139000]\n",
            " [    49  28000]\n",
            " [    57  33000]\n",
            " [    56  60000]\n",
            " [    49  39000]\n",
            " [    39  71000]\n",
            " [    47  34000]\n",
            " [    48  35000]\n",
            " [    48  33000]\n",
            " [    47  23000]\n",
            " [    45  45000]\n",
            " [    60  42000]\n",
            " [    39  59000]\n",
            " [    46  41000]\n",
            " [    51  23000]\n",
            " [    50  20000]\n",
            " [    36  33000]\n",
            " [    49  36000]]\n"
          ]
        }
      ],
      "source": [
        "label=data.iloc[:,-1].values\n",
        "x=data.iloc[:,:-1].values\n",
        "\n",
        "print('label : \\n',label)\n",
        "print('\\nx : \\n',x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wGpKlVltwDX",
        "outputId": "532116e6-2a91-43de-dfbb-e70bebb8bcbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "240\n",
            "[0, 0]\n"
          ]
        }
      ],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,label,test_size=0.4,random_state=61)\n",
        "\n",
        "sc=StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "y_pred  = []\n",
        "len_x=len(x_train[0])\n",
        "w = []\n",
        "b=0.2\n",
        "print(len_x)\n",
        "\n",
        "entries = len(x_train[:,0])\n",
        "print(entries)\n",
        "for weights in range(len_x):\n",
        "    w.append(0)\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFwgb6DstwDY"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    final = 1/(1+np.exp(-z))\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbhftx7PtwDZ"
      },
      "outputs": [],
      "source": [
        "def loss_func(y,a):\n",
        "    aT=a.T\n",
        "    j= (-1/entries) * (np.sum((aT*np.log(y)) + ((1-aT) * (np.log(1-y)))))\n",
        "    return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5_PXD0CtwDa"
      },
      "outputs": [],
      "source": [
        "def predict(inputs,m):\n",
        "    print(m)\n",
        "    y_pred=np.zeros(m);\n",
        "    for i in range(m):\n",
        "        if inputs[i] > 0.5:\n",
        "            y_pred[i] = 1\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAmrHViCtwDb"
      },
      "outputs": [],
      "source": [
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "    dw.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VpdOIM9twDc",
        "outputId": "25c3c257-26f3-4aa5-fd36-7534633149a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Weight :  [2.35625942 1.04217951]\n",
            "\n",
            "Bias :  -0.9112948033494777\n",
            "240\n",
            "pridiction of x_train: \n",
            " [1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "160\n",
            "pridiction of x_test: \n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "for i in range(3000):\n",
        "    y=sigmoid((np.dot(w,x_train.T)+b));\n",
        "    cost = loss_func(y,y_train);\n",
        "    dw = (1/entries) * (np.dot(x_train.T,(y-y_train.T).T));\n",
        "    db=(1/entries) * (np.sum(y-y_train.T))\n",
        "    w=w-(alpha * dw.T)\n",
        "    b=b-(alpha * db)\n",
        "\n",
        "print(\"\\nWeight : \",w)\n",
        "print(\"\\nBias : \" ,b)\n",
        "\n",
        "train_pred=sigmoid(np.dot(w,x_train.T)+b)\n",
        "\n",
        "test_pred=sigmoid(np.dot(w,x_test.T)+b)\n",
        "\n",
        "y_pred=predict(train_pred,x_train.shape[0])\n",
        "print('pridiction of x_train: \\n',y_pred)\n",
        "\n",
        "x_pred_test=predict(test_pred,x_test.shape[0])\n",
        "print('pridiction of x_test: \\n',x_pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3V6aWWStwDd",
        "outputId": "0af83b4a-4860-48ee-e6da-f2b5712b4211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "actal value\n",
            " [0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 1 0 0 0 1 0 0] (160,)\n",
            "\n",
            "accuracy score :  0.86875\n"
          ]
        }
      ],
      "source": [
        "print(\"actal value\\n\" ,y_test,y_test.shape)\n",
        "\n",
        "print(\"\\naccuracy score : \",accuracy_score(x_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS_UEdLPtwDe"
      },
      "source": [
        "# using Defualt Logistic Regressionation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8q2ENdbtwDf",
        "outputId": "0a0337fa-ed34-473e-8546-76030c219aae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy score :  0.86875\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lrmodel= LogisticRegression(random_state = 40)\n",
        "\n",
        "lrmodel.fit(x_train,y_train)\n",
        "\n",
        "pred=lrmodel.predict(x_test)\n",
        "\n",
        "print(\"\\naccuracy score : \",accuracy_score(pred,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWStG0mVtwDg"
      },
      "source": [
        "# Exercise 2"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Z-u9gmw1twDh"
      },
      "source": [
        "tenserflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HmtxTWptwDi"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGkgczthtwDj",
        "outputId": "449f201f-d4fd-47a3-eb11-b08185a427ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#step 2\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "\n",
        "num_features=784\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "print(x_train.shape)\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "print(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3\n",
        "num_classes = 10 # 0 to 9 digits\n",
        "num_features = 784 # 28*28\n",
        "learning_rate = 0.01\n",
        "training_steps = 1000\n",
        "batch_size = 256\n",
        "display_step = 50"
      ],
      "metadata": {
        "id": "Oe9m9JQ2uFVO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4\n",
        "train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHbZ3-DvuJz5",
        "outputId": "4686b6ba-4863-4a7b-c825-81a56b47e372"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5\n",
        "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
        "print(W)\n",
        "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdPrwFDauNpc",
        "outputId": "4a34e035-6002-4dda-a8eb-fcb2afd82179"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'weight:0' shape=(784, 10) dtype=float32, numpy=\n",
            "array([[1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>\n",
            "<tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6\n",
        "def logistic_regression(x):\n",
        "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))"
      ],
      "metadata": {
        "id": "R5px-QCYuQky"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 7\n",
        "def accuracy(y_pred, y_true):\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "metadata": {
        "id": "6HQX2ClOuWHG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 8\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "def run_optimization(x, y):\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = logistic_regression(x)\n",
        "        loss = cross_entropy(pred, y)\n",
        "    gradients = g.gradient(loss, [W, b])\n",
        "    optimizer.apply_gradients(zip(gradients, [W, b]))"
      ],
      "metadata": {
        "id": "a7Lt-uH_uYtu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 9\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "    run_optimization(batch_x, batch_y)\n",
        "    if step % display_step == 0:\n",
        "        prediction = logistic_regression(batch_x)\n",
        "        loss = cross_entropy(prediction, batch_y)\n",
        "        accurracy = accuracy(prediction, batch_y)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, accurracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIjgS6niubz3",
        "outputId": "860deac7-7ee3-40a3-81f6-abe5a4cfff2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 50, loss: 630.911621, accuracy: 0.832031\n",
            "step: 100, loss: 600.645386, accuracy: 0.816406\n",
            "step: 150, loss: 575.896667, accuracy: 0.832031\n",
            "step: 200, loss: 432.009369, accuracy: 0.871094\n",
            "step: 250, loss: 406.723328, accuracy: 0.839844\n",
            "step: 300, loss: 620.143005, accuracy: 0.851562\n",
            "step: 350, loss: 526.843201, accuracy: 0.847656\n",
            "step: 400, loss: 499.287781, accuracy: 0.835938\n",
            "step: 450, loss: 645.335449, accuracy: 0.855469\n",
            "step: 500, loss: 867.895447, accuracy: 0.753906\n",
            "step: 550, loss: 514.719482, accuracy: 0.855469\n",
            "step: 600, loss: 610.844604, accuracy: 0.804688\n",
            "step: 650, loss: 596.118530, accuracy: 0.851562\n",
            "step: 700, loss: 547.238708, accuracy: 0.843750\n",
            "step: 750, loss: 445.066895, accuracy: 0.886719\n",
            "step: 800, loss: 353.229828, accuracy: 0.886719\n",
            "step: 850, loss: 804.940002, accuracy: 0.789062\n",
            "step: 900, loss: 593.608887, accuracy: 0.843750\n",
            "step: 950, loss: 623.948853, accuracy: 0.843750\n",
            "step: 1000, loss: 824.046326, accuracy: 0.820312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 10\n",
        "prediction = logistic_regression(x_test)\n",
        "\n",
        "print(\"Test Accuracy: %f\" % accuracy(prediction, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjtQD8xiulry",
        "outputId": "7ac2bab2-e38a-4b27-995c-6d8319d37b0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.836600\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lab7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}